{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#Generate random integer values\n",
    "from random import seed\n",
    "from random import randint\n",
    "import math\n",
    "#Regular Expressions\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'This is an example sentence, and it is actually a beautiful one.'\n",
    "fdist = FreqDist(word_tokenize(sent))\n",
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions:\n",
    "#The following function receives a string indicating the path to follow and\n",
    "#and returns the data in the file.\n",
    "def openFile(s):\n",
    "    file = open(s)\n",
    "    data_file = file.read()\n",
    "    file.close()\n",
    "    return data_file\n",
    "#The following function receives the data from the stop word's file, splits them\n",
    "#and extends them.\n",
    "def cleanStop(sw):\n",
    "    csw = [ts for ts in sw.split()]\n",
    "    esw = ['.', ',',';',':', '/','\"', '?', '!', '¡', '<', '>', 'El', '>El']\n",
    "    csw.extend(esw)\n",
    "    return csw\n",
    "#   The following function utilizes beautiful soup to obtain the methodologies\n",
    "#   and put them into\n",
    "def bsMeth(s):\n",
    "    # Use beautiful Soup to separate the methodologies\n",
    "    with open(s) as fp:\n",
    "        soup = BeautifulSoup(fp, 'xml')\n",
    "    all = soup.find_all('Problema')\n",
    "\n",
    "    counter = 1\n",
    "    problem = \"\"\n",
    "    for met in soup.find_all('Problema'):\n",
    "        [s.extract() for s in met.findAll('Problema')]\n",
    "        ######print(\"*Metodologia\", counter)\n",
    "        #####print(met)\n",
    "        problem = problem + str(met) + \"\\n\"\n",
    "        #####print(\"\\n\")\n",
    "        counter += 1\n",
    "    return problem\n",
    "#   The following function receives the methodologies and separates them. It\n",
    "#   creates a dictionary-matrix with the following structure:\n",
    "#   Methodologies-Number-Word\n",
    "def sepMeth(justificacion):\n",
    "    met_matrix = {}\n",
    "    counter_met = 1\n",
    "    for met in justificacion:\n",
    "        met_vector = {}\n",
    "        counter_word = 1\n",
    "        met = [d for d in met.split()]\n",
    "        for word in met:\n",
    "            met_vector[counter_word] = word\n",
    "            counter_word += 1\n",
    "        if(met_vector):\n",
    "            met_vector.popitem()\n",
    "        met_matrix[\"Problema\" + str(counter_met)] = met_vector\n",
    "        counter_met += 1\n",
    "    return met_matrix\n",
    "\n",
    "#   The following function receives the Stop Words and the Methodologies and\n",
    "#   removes the stop words from the methodologies (It basically returns the\n",
    "#   methodologies clean.).\n",
    "def cleanMeth(sw, meth):\n",
    "    cleanMeth_matrix = {}\n",
    "    for m, m_vector in meth.items():\n",
    "        cleanMeth_vector = {}\n",
    "        for num, word in m_vector.items():\n",
    "            word = word.lower()\n",
    "            word = re.sub('[^a-zñáéíóú]', '', word)\n",
    "            if (word not in sw) and word:\n",
    "                cleanMeth_vector[num] = word\n",
    "        cleanMeth_matrix[m] = cleanMeth_vector\n",
    "    return cleanMeth_matrix\n",
    "#   The following function receives the clean methodologies and returns a\n",
    "#   dictionary with the structure Methodologies-WordVector\n",
    "def listMeth(meth):\n",
    "    listMethMatrix = {}\n",
    "    for m, m_vector in meth.items():\n",
    "        listMethVector = []\n",
    "        for num, word in m_vector.items():\n",
    "            listMethVector.append(word)\n",
    "        listMethMatrix[m] = listMethVector\n",
    "    return listMethMatrix\n",
    "#   The following function gets the frequency of each word and divides them by\n",
    "#   the amount of words in the document.\n",
    "def relFreq(meth):\n",
    "    freqMethMatrix = {}\n",
    "    for m, m_vector in meth.items():\n",
    "        freqMethVector = {}\n",
    "        sizeM = len(m_vector)\n",
    "        freq = nltk.FreqDist(m_vector)\n",
    "        for word, frequency in freq.most_common():\n",
    "            if word not in freqMethVector:\n",
    "#                 print('Frequency: {}, SizeM: {}'.format(frequency, sizeM))\n",
    "                freqMethVector[word] = frequency/sizeM\n",
    "        freqMethMatrix[m] = freqMethVector\n",
    "    return freqMethMatrix\n",
    "#   The following function opens the frequency for the most common words in\n",
    "#   spanish and returns a dictionary with the following structure: Word-Freq\n",
    "def mostCommon():\n",
    "    f = open(\"frecuencia.txt\", \"r\")\n",
    "    mostCommonVector = {}\n",
    "    for line in f:\n",
    "        line = [d for d in line.split()]\n",
    "        line[2] = line[2].replace(',', '')\n",
    "        mostCommonVector[line[1]] = line[2]\n",
    "    return mostCommonVector\n",
    "#   The following function receives the dictionary with the sections and\n",
    "#   returns a Dictionary-Matrix with the following form:\n",
    "#   Section#-Word:LogFrequency\n",
    "def logFreq(meth, common):\n",
    "    logFreqMatrix = {}\n",
    "    for m, methVector in meth.items():\n",
    "        logFreqVector = {}\n",
    "        for word in methVector:\n",
    "            ####print(\"Word:\", word)\n",
    "            if (word in common):\n",
    "                ####print(\"Word:\", word)\n",
    "                ####print(\"Value:\", common[word])\n",
    "                logFreqVector[word] = np.log(float(common[word]))\n",
    "            else:\n",
    "                logFreqVector[word] = 0.0\n",
    "        logFreqMatrix[m] = logFreqVector\n",
    "    return logFreqMatrix\n",
    "#   The following function receives a single dictionary dictionary of specific\n",
    "#   sections. It returns a vocabulary based on all the words that appear in the\n",
    "#   the complete set of documents.\n",
    "def obtainVocSingle(D):\n",
    "    voc = []\n",
    "    for s, svec in D.items():\n",
    "        for word in svec:\n",
    "            if word not in voc:\n",
    "                voc.append(word)\n",
    "    return voc\n",
    "#   The following function receives two dictionaries of specific sections. It returns\n",
    "#   It returns a vocabulary based on all the words that appear in the complete set of\n",
    "#   documents.\n",
    "def obtainVocDouble(d1, d2):\n",
    "    voc = []\n",
    "    for s, svec in d1.items():\n",
    "        for word in svec:\n",
    "            if word not in voc:\n",
    "                voc.append(word)\n",
    "    for s, svec in d2.items():\n",
    "        for word in svec:\n",
    "            if word not in voc:\n",
    "                voc.append(word)\n",
    "    return voc\n",
    "\n",
    "#   The following function creates a vocabulary for all the words that appear in\n",
    "#   justifications.\n",
    "def obtainVoc(TSU, Lic, Maestria, Doctorado):\n",
    "    vocabulary = []\n",
    "    for m, mvec in TSU.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    for m, mvec in Lic.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    for m, mvec in Maestria.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    for m, mvec in Doctorado.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    return vocabulary\n",
    "#   The following function creates a vocabulary for all the words that appear in\n",
    "#   justifications.\n",
    "def obtainVoc3(TSU, Lic, Maestria):\n",
    "    vocabulary = []\n",
    "    for m, mvec in TSU.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    for m, mvec in Lic.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    for m, mvec in Maestria.items():\n",
    "        for word in mvec:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "    return vocabulary\n",
    "#   The following function utilizes the vocabulary to dimensionate the relative\n",
    "#   frequency.\n",
    "def dimRelFreq(matrix, voc):\n",
    "    dimRelFreqMatrix = {}\n",
    "    for j, jvec in matrix.items():\n",
    "        dimRelFreqVec = {}\n",
    "        for word in voc:\n",
    "            if word in jvec:\n",
    "                dimRelFreqVec[word] = jvec[word]\n",
    "            else:\n",
    "                dimRelFreqVec[word] = 0.0\n",
    "        dimRelFreqMatrix[j] = dimRelFreqVec\n",
    "    return dimRelFreqMatrix\n",
    "\n",
    "#   The following function subcatenates two matrices, it subtracts one from the\n",
    "#   vector from the other and return the result in the following form\n",
    "#   Justification-ResultantVector\n",
    "def substract(A, B):\n",
    "    resultantMatrix = {}\n",
    "    for (a, avec), (b, bvec) in zip(A.items(), B.items()):\n",
    "        resultantVec = []\n",
    "        for (wa, va), (wb, vb) in zip(avec.items(), bvec.items()):\n",
    "            resultantVec.append(va-vb)\n",
    "        resultantMatrix[a] = resultantVec\n",
    "    return resultantMatrix\n",
    "#   The following function substracts entrance by entrance two dictionary\n",
    "#   vectors. It returns the result of the subtraction but in a vector, no longer\n",
    "#   a dictionary.\n",
    "def substractVec(A, B):\n",
    "    resultantVec = []\n",
    "    for (wa, va), (wb, vb) in zip(A.items(), B.items()):\n",
    "        resultantVec.append(va-vb)\n",
    "    return resultantVec\n",
    "#   The following function receives two dictionary matrixes, and concatenates\n",
    "#   their respective vectors row by row\n",
    "def concatenate(A, B):\n",
    "    resultantMatrix = []\n",
    "    for(a, avec), (b, bvec) in zip(A.items(), B.items()):\n",
    "        resultantVec = []\n",
    "        resultantVec = avec + bvec\n",
    "        ###print(len(resultantVec))\n",
    "        resultantMatrix.append(resultantVec)\n",
    "    return resultantMatrix\n",
    "#   The following function receives two list-vectors and concatenates them in\n",
    "#   the order A+B. It returns the concatenated vector.\n",
    "def concatenateVec(A, B):\n",
    "    resultantVec = A + B\n",
    "    return resultantVec\n",
    "#   The followign function receives two dictionary list-vector and concatenates\n",
    "#   them vector-entry by vector-entry. It returns that concatenation.\n",
    "def concatenateDictionaries(A, B):\n",
    "    resultantMatrix = []\n",
    "    for(a, avec), (b, bvec) in zip(A.items(), B.items()):\n",
    "        resultantVec = []\n",
    "        for (wa, va) in avec.items():\n",
    "            resultantVec.append(va)\n",
    "        for(wb, vb) in bvec.items():\n",
    "            resultantVec.append(vb)\n",
    "        resultantMatrix.append(resultantVec)\n",
    "    return resultantMatrix\n",
    "#   The following function receives a dictionary-dictionary and returns a\n",
    "#   a dictionary-list.\n",
    "def enlist(A):\n",
    "    resultantMatrix = {}\n",
    "    for (a, avec) in (A.items()):\n",
    "        resultantVec = []\n",
    "        for(w, v) in avec.items():\n",
    "            resultantVec.append(v)\n",
    "        resultantMatrix[a] = resultantVec\n",
    "    return resultantMatrix\n",
    "#   The following function receives a dictionary-vector and returns a\n",
    "#   list.\n",
    "def enlistVec(A):\n",
    "    resultantVec = []\n",
    "    for(w, v) in A.items():\n",
    "        resultantVec.append(v)\n",
    "    return resultantVec\n",
    "\n",
    "#   The following function takes two matrixes A, B and returns a training matrix\n",
    "#   and a classification matrix. The training matrix contains all the related\n",
    "#   vectors in a single matrix.\n",
    "def training(A, B):\n",
    "    trainingMatrix = []\n",
    "    classMatrix = []\n",
    "    for av in A:\n",
    "        trainingMatrix.append(av)\n",
    "        classMatrix.append(-1.0)\n",
    "    for bv in B:\n",
    "        trainingMatrix.append(bv)\n",
    "        classMatrix.append(1.0)\n",
    "    return (trainingMatrix, classMatrix)\n",
    "#   The following function takes fifty vectors from A, B matrixes and stores\n",
    "#   them in a single matrix (This will be our training matrix). The Function\n",
    "#   also creates a vector as the classification vector.\n",
    "def trainingR(A, B, C, D, E, F):\n",
    "    trainingMatrix = []\n",
    "    classMatrix = []\n",
    "    for av in A:\n",
    "        trainingMatrix.append(av)\n",
    "        classMatrix.append(-1.0)\n",
    "    for cv in C:\n",
    "        trainingMatrix.append(cv)\n",
    "        classMatrix.append(-1.0)\n",
    "    for ev in E:\n",
    "        trainingMatrix.append(ev)\n",
    "        classMatrix.append(-1.0)\n",
    "    for bv in B:\n",
    "        trainingMatrix.append(bv)\n",
    "        classMatrix.append(1.0)\n",
    "    for dv in D:\n",
    "        trainingMatrix.append(dv)\n",
    "        classMatrix.append(1.0)\n",
    "    for fv in F:\n",
    "        trainingMatrix.append(fv)\n",
    "        classMatrix.append(1.0)\n",
    "    return(trainingMatrix, classMatrix)\n",
    "#   The following function receives two dictionaries and returns the vectors\n",
    "#   in the dictionary concatenated with the other matrix and a classification\n",
    "#   matrix.\n",
    "def trainingL(A, B):\n",
    "    tMatrix = []\n",
    "    cMatrix = []\n",
    "    for a, avec in A.items():\n",
    "        tMatrix.append(avec)\n",
    "        cMatrix.append(-1.0)\n",
    "    for b, bvec in B.items():\n",
    "        tMatrix.append(bvec)\n",
    "        cMatrix.append(1.0)\n",
    "    return (tMatrix, cMatrix)\n",
    "def trainingLR(A, B, C, D, E, F):\n",
    "    trainingMatrix = []\n",
    "    classMatrix = []\n",
    "    for a, avec in A.items():\n",
    "        trainingMatrix.append(avec)\n",
    "        classMatrix.append(-1.0)\n",
    "    for c, cvec in C.items():\n",
    "        trainingMatrix.append(cvec)\n",
    "        classMatrix.append(-1.0)\n",
    "    for e, evec in E.items():\n",
    "        trainingMatrix.append(evec)\n",
    "        classMatrix.append(-1.0)\n",
    "    for b, bvec in B.items():\n",
    "        trainingMatrix.append(bvec)\n",
    "        classMatrix.append(1.0)\n",
    "    for d, dvec in D.items():\n",
    "        trainingMatrix.append(dvec)\n",
    "        classMatrix.append(1.0)\n",
    "    for f, fvec in F.items():\n",
    "        trainingMatrix.append(fvec)\n",
    "        classMatrix.append(1.0)\n",
    "    return(trainingMatrix, classMatrix)\n",
    "###############################################\n",
    "#           Science Contribution              #\n",
    "###############################################\n",
    "\n",
    "#   The following function receives a dimensionalized vector from one of the\n",
    "#   possible classes of justifications and returns a test vector.\n",
    "def obtainTest(A, B):\n",
    "    # seed random number generator\n",
    "    seed(1)\n",
    "    # generate the random number\n",
    "    r = randint(0, len(A))\n",
    "    counter = 0\n",
    "    testRF = {}\n",
    "    testLF = {}\n",
    "    for (wordA, vwordA), (wordB, vwordB) in zip(A.items(), B.items()):\n",
    "        if counter == r:\n",
    "            testRF = vwordA\n",
    "            testLF = vwordB\n",
    "            impWord = wordA\n",
    "        counter += 1\n",
    "    A.pop(impWord)\n",
    "    B.pop(impWord)\n",
    "    return (testRF, testLF)\n",
    "\n",
    "#   The following function receives a Matrix and returns a random vector in it.\n",
    "#   This vector will be use as a representative vector of the class in order\n",
    "#   to classify a text file as easier or more difficult than it.\n",
    "def random(A, B):\n",
    "    seed(1)\n",
    "    r = randint(0, len(A))\n",
    "    counter = 0\n",
    "    randRF = []\n",
    "    randLF = []\n",
    "    for (wordA, vwordA), (wordB, vwordB) in zip(A.items(), B.items()):\n",
    "        if counter == r:\n",
    "            randRF = vwordA\n",
    "            randLF = vwordB\n",
    "            impWord = wordA\n",
    "        counter += 1\n",
    "    A.pop(impWord)\n",
    "    B.pop(impWord)\n",
    "    return(randRF, randLF)\n",
    "#   The following function receives a set of vectors and returns a random vector\n",
    "#   from the collection.\n",
    "def randomR(A):\n",
    "    seed()\n",
    "    print(\"Length of vector for random choice:\", len(A))\n",
    "    random = randint(0, len(A)-1)\n",
    "    randVector = A[random]\n",
    "    return randVector, random\n",
    "#   The following function receives a set of matrixes and returns a list of random\n",
    "#   vectors, one for each matrix.\n",
    "def obtainRandomVectorsR(A, B, C, D):\n",
    "    vecList = []\n",
    "    vecPosition = []\n",
    "    randomVecA, randomPositionA = randomR(A)\n",
    "    vecList.append(randomVecA)\n",
    "    vecPosition.append(randomPositionA)\n",
    "    randomVecB, randomPositionB = randomR(B)\n",
    "    vecList.append(randomVecB)\n",
    "    vecPosition.append(randomPositionB)\n",
    "    randomVecC, randomPositionC = randomR(C)\n",
    "    vecList.append(randomVecC)\n",
    "    vecPosition.append(randomPositionC)\n",
    "    return vecList\n",
    "#   The following function receives a set of matrixes and returns a list of random\n",
    "#   vectors, one for each matrix.\n",
    "def obtainRandomVectors3(A, B, C):\n",
    "    vecList = []\n",
    "    vecPosition = []\n",
    "    randomVecA, randomPositionA = randomR(A)\n",
    "    vecList.append(randomVecA)\n",
    "    vecPosition.append(randomPositionA)\n",
    "    randomVecB, randomPositionB = randomR(B)\n",
    "    vecList.append(randomVecB)\n",
    "    vecPosition.append(randomPositionB)\n",
    "    randomVecC, randomPositionC = randomR(C)\n",
    "    vecList.append(randomVecC)\n",
    "    vecPosition.append(randomPositionC)\n",
    "    return vecList, vecPosition\n",
    "#   The following function receives eight matrixes and returns two lists: the\n",
    "#   first list contains all the random RF vectors and the second list contains\n",
    "#   LF vectors.\n",
    "def obtainRandomVectors(A, B, C, D, E, F, G, H):\n",
    "    vecListRF = [None]*4\n",
    "    vecListLF = [None]*4\n",
    "    (vecListRF[0], vecListLF[0]) = random(A, B)\n",
    "    (vecListRF[1], vecListLF[1]) = random(C, D)\n",
    "    (vecListRF[2], vecListLF[2]) = random(E, F)\n",
    "    (vecListRF[3], vecListLF[3]) = random(G, H)\n",
    "\n",
    "    return (vecListRF, vecListLF)\n",
    "#   The following function receives eight matrixes two test vector related to\n",
    "#   RF and LF, the general training matrix and its classyfying vector. The\n",
    "#   function returns the maximum level of difficulty of the text.\n",
    "def obtainGrade(lRF, lLF, testRF, testLF, tMatrix, CV):\n",
    "    #Train the SVM\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(tMatrix, CV)\n",
    "\n",
    "    grade = 0\n",
    "    goodGrade = 0\n",
    "    ##print(testRF)\n",
    "    for (vecRF, vecLF) in zip(lRF, lLF):\n",
    "        testSubRF = substractVec(testRF, vecRF)\n",
    "        testSubLF = substractVec(testLF, vecLF)\n",
    "        conTest = concatenateVec(testSubRF, testSubLF)\n",
    "        result = clf.predict([conTest])\n",
    "        #print(\"Resultado: \")\n",
    "        #print(result[0])\n",
    "        if (result[0] == -1.0 or goodGrade>=3):\n",
    "            #print(\"Entering results:\")\n",
    "            #print(\"Grade: \", grade)\n",
    "            if(grade == 0):\n",
    "                print(\"Your text is as good as TSU.\")\n",
    "            elif(grade == 1):\n",
    "                print(\"Your text is as good as Lic.\")\n",
    "            elif(grade == 2):\n",
    "                print(\"Your text is as good as Maestria.\")\n",
    "            elif(grade >= 3):\n",
    "                print(\"Your text is as good as Doctorado.\")\n",
    "            break\n",
    "        else:\n",
    "            goodGrade += 1\n",
    "\n",
    "        grade = grade + 1\n",
    "#   The following function receives a list with the respective centroids, a\n",
    "#   vector test in order to try and the training matrix with its respective\n",
    "#   classes.\n",
    "def obtainGradeR(centroidList, testRF, testLF, tMatrix, CV):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(tMatrix, CV)\n",
    "\n",
    "    grade = 0\n",
    "    goodGrade = 0\n",
    "    #print(testRF)\n",
    "    #print(len(testRF))\n",
    "    testRF = enlistVec(testRF)\n",
    "    testLF = enlistVec(testLF)\n",
    "    conTest = concatenateVec(testRF, testLF)\n",
    "    conTest = np.array(conTest)\n",
    "    #print(conTest)\n",
    "    #print(len(conTest))\n",
    "    result = clf.predict([conTest])\n",
    "    for vec in centroidList:\n",
    "        vec = np.array(vec)\n",
    "        #print(vec)\n",
    "        #print(len(vec))\n",
    "        subVec = conTest - vec\n",
    "        #print(subVec)\n",
    "        #print(len(subVec))\n",
    "        result = clf.predict([subVec])\n",
    "        #print(result)\n",
    "        if (result[0] == -1.0 or goodGrade>=3):\n",
    "            if(grade == 0):\n",
    "                print(\"Your text is as good as TSU.\")\n",
    "            elif(grade == 1):\n",
    "                print(\"Your text is as good as Lic.\")\n",
    "            elif(grade == 2):\n",
    "                print(\"Your text is as good as Maestria.\")\n",
    "            elif(grade >= 3):\n",
    "                print(\"Your text is as good as Doctorado.\")\n",
    "            break\n",
    "        else:\n",
    "            goodGrade += 1\n",
    "\n",
    "        grade = grade + 1\n",
    "#   The following function receives a test vector and a list of random vectors.\n",
    "#   It returns the grade of the vector.\n",
    "def obtainGradeRandom(vector, vector_list, clf):\n",
    "    grade = 0\n",
    "    goodGrade = 0\n",
    "    for vec in vector_list:\n",
    "        vector = vector - vec\n",
    "        result = clf.predict([vector])\n",
    "        #print(\"Result: \", result)\n",
    "        if (result[0] == -1.0 or goodGrade>=3):\n",
    "            if(grade == 0):\n",
    "                #print(\"Your text is as good as TSU.\")\n",
    "                return 0\n",
    "            elif(grade == 1):\n",
    "                #print(\"Your text is as good as Lic.\")\n",
    "                return 1\n",
    "            elif(grade >= 2):\n",
    "                #print(\"Your text is as good as Maestria.\")\n",
    "                return 2\n",
    "            break\n",
    "        else:\n",
    "            goodGrade += 1\n",
    "\n",
    "        grade = grade + 1\n",
    "#   The following function receives a testMatrix, its vector classification and a\n",
    "#   list of random vector. It returns the accuracy of the evaluator.\n",
    "def randomEvaluator(test_matrix, classification, vector_list, clf):\n",
    "    acc = 0\n",
    "    print(\"Test Matrix: \")\n",
    "    print(test_matrix)\n",
    "    print(\"Length of Random: \", len(test_matrix))\n",
    "    for i in range(len(test_matrix)):\n",
    "        grade = obtainGradeRandom(test_matrix[i], vector_list, clf)\n",
    "        #print(\"Grade: \", grade)\n",
    "        #print(\"Classification: \", int(classification[i]))\n",
    "        if grade == int(classification[i]):\n",
    "            acc += 1\n",
    "    return acc/len(test_matrix)\n",
    "# #   The following function receives a testMatrix, its vector classification and a\n",
    "# #   list of random vector and the plain justifications. It returns the justification\n",
    "# #   and its respective classification wether it was wrong or not.\n",
    "def getJustificationEvaluation(test_matrix, classification, vector_list, clf, justificacionTSU, justificacionLic, justificacionMaestria):\n",
    "    acc = 0\n",
    "    print(\"Test Matrix: \")\n",
    "    print(test_matrix)\n",
    "    print(\"Length of Random: \", len(test_matrix))\n",
    "    counter = 1\n",
    "    for i in range(len(test_matrix)):\n",
    "        grade = obtainGradeRandom(test_matrix[i], vector_list, clf)\n",
    "        #print(\"Grade: \", grade)\n",
    "        #print(\"Classification: \", int(classification[i]))\n",
    "        if counter <= 11:\n",
    "            print(\"Justificacion de TSU:\")\n",
    "            if grade == int(classification[i]):\n",
    "                print(\"Justificacion Correcta: \")\n",
    "                print(justificacionTSU[counter])\n",
    "                acc += 1\n",
    "            else:\n",
    "                print(\"Justificacion Incorrecta: \")\n",
    "                print(justificacionTSU[counter])\n",
    "            counter += 1\n",
    "        elif 12<= counter <=23:\n",
    "            print(\"Justificaciones de Licenciatura\")\n",
    "            if grade == int(classification[i]):\n",
    "                print(\"Justificacion Correcta: \")\n",
    "                print(justificacionLic[counter])\n",
    "                acc += 1\n",
    "            else:\n",
    "                print(\"Justificacion Incorrecta: \")\n",
    "                print(justificacionLic[counter])\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(\"Justificaciones de Maestria: \")\n",
    "            if grade == int(classification[i]):\n",
    "                print(\"Justificacion Correcta: \")\n",
    "                print(justificacionMaestria[counter])\n",
    "                acc += 1\n",
    "            else:\n",
    "                print(\"Justificacion Incorrecta: \")\n",
    "                print(justificacionMaestria[counter])\n",
    "            counter += 1\n",
    "\n",
    "    return acc/len(test_matrix)\n",
    "#   The following function receives all the justifications for all the different\n",
    "#   scholar levels and a list for the positions of the random vectors.\n",
    "#   It returns the random selected vectors and prints them in screen.\n",
    "def getRandomJustifications(list, A, B, C):\n",
    "    print(\"TSU random justification:\")\n",
    "    print(A[list[0]+6])\n",
    "    print(\"Lic. random justification: \")\n",
    "    print(A[list[1]+6])\n",
    "    print(\"Maestria random justification: \")\n",
    "    print(A[list[2]+6])\n",
    "\n",
    "\n",
    "#   The following function receives two matrixes, one related to the Relative\n",
    "#   Frequency vectors and one related to the Logarithmic Frequency. It concatenates\n",
    "#   them, tranforms them into a vector instead of a dictionary and returns the\n",
    "#   centroid of them all.\n",
    "def centroid(A, B):\n",
    "    A = enlist(A)\n",
    "    B = enlist(B)\n",
    "    M = concatenate(A, B)\n",
    "    #Transform into a numpy array\n",
    "    Marray = np.array(M)\n",
    "    length = len(Marray)\n",
    "    centroid = np.zeros(33642)\n",
    "    for vec in Marray:\n",
    "        centroid = np.add(centroid, vec)\n",
    "    centroid = centroid*(1/len(M[0]))\n",
    "    return centroid\n",
    "\n",
    "def centroidR(A, B):\n",
    "    A = enlist(A)\n",
    "    B = enlist(B)\n",
    "    M = concatenate(A, B)\n",
    "    length = len(M)\n",
    "    centroid = np.zeros(33642)\n",
    "    for i in range(length):\n",
    "        for j in range(len(M[0])):\n",
    "            centroid[j] = centroid[j] + M[i][j]\n",
    "    for j in range(len(M[0])):\n",
    "        centroid[j] = centroid[j]/(len(M[0]))\n",
    "    return centroid\n",
    "#   The following function receives a matrix and returns its centroid.\n",
    "def centroidRR(A):\n",
    "    centroid = np.zeros(len(A[0]))\n",
    "    for vec in A:\n",
    "        centroid = centroid + vec\n",
    "    return centroid/(len(A))\n",
    "#   The following function receives the test matrix, the classification vector,\n",
    "#   the centroid list and the svm classifier. It returns the accuracy of the centroid\n",
    "#   evaluator.\n",
    "def centroidEvaluator(test_matrix, classification, centroids, clf):\n",
    "    acc = 0\n",
    "    for i in range(len(test_matrix)):\n",
    "        grade = obtainGradeRandom(test_matrix[i], centroids, clf)\n",
    "        #print(\"Grade: \", grade)\n",
    "        #print(\"Classification: \", int(classification[i]))\n",
    "        if grade == int(classification[i]):\n",
    "            acc += 1\n",
    "    return acc/len(test_matrix)\n",
    "#   The following function receives four matrixes and returns a list of centroids.\n",
    "#   One for each matrix.\n",
    "def obtainCentroids(A, B, C, D):\n",
    "    list = []\n",
    "    list.append(centroidRR(A))\n",
    "    list.append(centroidRR(B))\n",
    "    list.append(centroidRR(C))\n",
    "    list.append(centroidRR(D))\n",
    "    return list\n",
    "#   The following function receives four matrixes and returns a list of centroids.\n",
    "#   One for each matrix.\n",
    "def obtainCentroids3(A, B, C):\n",
    "    list = []\n",
    "    list.append(centroidRR(A))\n",
    "    list.append(centroidRR(B))\n",
    "    list.append(centroidRR(C))\n",
    "    return list\n",
    "#   The following function removes the len zero vectors from the dictionary and\n",
    "#   returns a dictionary.\n",
    "def removeZero(GM):\n",
    "    l = []\n",
    "    for n, w_vec in GM.items():\n",
    "        if len(w_vec) == 0:\n",
    "            l.append(n)\n",
    "    for e in l:\n",
    "        del GM[e]\n",
    "    return GM\n",
    "\n",
    "#   The follwing function receives a matrix and eliminates the zero lenght vectors\n",
    "#   from it.\n",
    "def cleanVector(A):\n",
    "    return removeZero(A)\n",
    "\n",
    "#   The following function receives the four grade matrixes and eliminates the\n",
    "#   zero length vectors from it.\n",
    "def cleanVectors(A, B, C, D):\n",
    "    \n",
    "    return removeZero(A), removeZero(B), removeZero(C), removeZero(D)\n",
    "#   The following function gets the size of the smallest vector in the dictionary\n",
    "#   vector-word matrix.\n",
    "def smallest(GM):\n",
    "    smallestValue = 1000000\n",
    "    for n, w_vec in GM.items():\n",
    "        if smallestValue > len(w_vec):\n",
    "            smallestValue = len(w_vec)\n",
    "    return smallestValue\n",
    "#   The following function gets the size of the biggest vector in the dictionry\n",
    "#   vector-word matrix.\n",
    "def biggest(GM):\n",
    "    biggestValue = 0\n",
    "    for n, w_vec in GM.items():\n",
    "        if biggestValue < len(w_vec):\n",
    "            biggestValue = len(w_vec)\n",
    "    return biggestValue\n",
    "#   The following function receives a grade matrix and returns the average size\n",
    "#   of the vectors in it.\n",
    "def average(GM):\n",
    "    averageValue = 0\n",
    "    allElements = len(GM)\n",
    "    for n, w_vec in GM.items():\n",
    "        averageValue = averageValue + len(w_vec)\n",
    "    return (averageValue/allElements)\n",
    "#   The following function receives a grade matrix and returns a dictionary with\n",
    "#   the size of the smallest vector, the biggest vector and the average sizes\n",
    "#   of the vectors.\n",
    "def returnSizes(GM):\n",
    "    sizes = {}\n",
    "    sizes['Smallest'] = smallest(GM)\n",
    "    sizes['Biggest'] = biggest(GM)\n",
    "    sizes['Average'] = average(GM)\n",
    "    return sizes\n",
    "#   The following function receives two grade matrixes dimensionalized and concatenated\n",
    "#   and returns the substraction of both of them.\n",
    "def subInc(A, B):\n",
    "    matrix = []\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    for vecA in A:\n",
    "        for vecB in B:\n",
    "            matrix.append(vecA - vecB)\n",
    "    return matrix\n",
    "#   The following function receives two matrices dimensionalized and concatenated\n",
    "#   and returns their conmutative combination in two differente matrices. The plusOne\n",
    "#   and the minusOne.\n",
    "def comData(A, B):\n",
    "    plusOne = subInc(B, A)\n",
    "    minusOne = subInc(A, B)\n",
    "    return plusOne, minusOne\n",
    "#   The following function receives a matrix and returns the 80 percent of the values\n",
    "#   in one matrix and the other twenty in another matrix.\n",
    "def eightyTwenty(A):\n",
    "    m = np.array([])\n",
    "    twenty = math.ceil(len(A)*(1/5))\n",
    "    for i in range(twenty):\n",
    "        np.append(m, A[i], 0)\n",
    "        np.delete(A, i, 0)\n",
    "    return A, m\n",
    "#   The following function receives the plusOne and minusOne version for all the grades\n",
    "#   and returns the training matrix along with its classification vector.\n",
    "def allTogetherNow(POT, MOT, POL, MOL, POM, MOM):\n",
    "    M = np.array([])\n",
    "    y = np.array([])\n",
    "    M = np.append(POT, POL, 0)\n",
    "    M = np.append(M, POM, 0)\n",
    "    M = np.append(M, MOT, 0)\n",
    "    M = np.append(M, MOL, 0)\n",
    "    M = np.append(M, MOM, 0)\n",
    "    y1 = np.ones(len(POT) + len(POL) + len(POM))\n",
    "    y2 = np.zeros(len(MOT) + len(MOL) + len(MOM))\n",
    "    y2 = y2-1\n",
    "    y = np.append(y1, y2, 0)\n",
    "    return M, y\n",
    "#   The following function receives plusOne and minusOne version for all the grades\n",
    "#   and returns the training matrix along with its classification vector.\n",
    "def allTogetherNow(POT, MOT, POL, MOL):\n",
    "    M = np.array([])\n",
    "    y = np.array([])\n",
    "    M = np.append(POT, POL, 0)\n",
    "    M = np.append(M, MOT, 0)\n",
    "    M = np.append(M, MOL, 0)\n",
    "    y1 = np.ones(len(POT) + len(POL))\n",
    "    y2 = np.zeros(len(MOT) + len(MOL))\n",
    "    y2 = y2-1\n",
    "    y = np.append(y1, y2, 0)\n",
    "    return M, y\n",
    "#   The following function receives a plusOne and a minusOne matrix. It returns a \n",
    "#   an appended matrix of the both along with its classification vector.\n",
    "def allTogetherNowDouble(PO, MO):\n",
    "    M = np.array([])\n",
    "    y = np.array([])\n",
    "    M = np.append(PO, MO, axis = 0)\n",
    "    y1 = np.ones(len(PO))\n",
    "    y2 = np.zeros(len(MO))\n",
    "    y = np.append(y1, y2, axis = 0)\n",
    "    return M, y\n",
    "\n",
    "#   The following function receives a dictionary-list matrix and returns eighty\n",
    "#   percent of the vectors in one matrix and the other twenty percent in another\n",
    "#   matrix.\n",
    "def divideEightyTwenty(M):\n",
    "    twenty = {}\n",
    "    eighty = {}\n",
    "    counter = 0\n",
    "    stop = int(len(M)/5)\n",
    "    for v, vvec in M.items():\n",
    "        if counter <= stop:\n",
    "            twenty[v] = vvec\n",
    "        else:\n",
    "            eighty[v] = vvec\n",
    "        counter += 1\n",
    "    return twenty, eighty\n",
    "#   The following function receives two matrixes the plusOne and the minusOne and\n",
    "#   returns it's respective trainingMatrix with their related classification vector.\n",
    "def togetherNow(A, B):\n",
    "    M = np.array([])\n",
    "    y = np.array([])\n",
    "    M = np.append(A,B,0)\n",
    "    y1 = np.ones(len(A))\n",
    "    y2 = np.zeros(len(B))\n",
    "    y2 = y2-1\n",
    "    y = np.append(y1, y2, 0)\n",
    "    return M, y\n",
    "#   The following function divides our whole training set into 80 percent for\n",
    "#   training and 20 percent for testing. It returns both matrixes.\n",
    "def getEightyTwenty(M, y):\n",
    "    print(\"Enter Eighty Twenty\")\n",
    "    np.c_[M, y]\n",
    "    length = len(M)\n",
    "    testMatrix = np.array([])\n",
    "    print(int(length*(1/5)))\n",
    "    seed(1)\n",
    "    for i in range(int(length*(1/5))):\n",
    "        print(i)\n",
    "        random = randint(0, length)\n",
    "        np.append(testMatrix, M[random])\n",
    "        np.delete(M, random, 0)\n",
    "    with open('traingMatrix.txt', 'wb') as f:\n",
    "        for line in trainingMatrix:\n",
    "            np.savetxt(f, line, fmt = '%.2f')\n",
    "    return trainingMatrix, testMatrix\n",
    "#   The following function receives the M matrix which corresponds to the training\n",
    "#   objects and the test matrix. It first trains the SVM for later test the accuracy\n",
    "#   of it five times. Finally it returns the five accuracies along with its standard\n",
    "#   deviation.\n",
    "def testAccuracy(M, tM):\n",
    "    #Get the training Matrix just values\n",
    "    M = np.array(M)\n",
    "    y = M[:, len(M[0])-1]\n",
    "    M = np.delete(M, len(M[0])-1, 1)\n",
    "    yt = tM[:, len(tM[0])-1]\n",
    "    tM = np.delete(tM, len(tM[0])-1, 1)\n",
    "    # Train the svm\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(M)\n",
    "    for i in range(5):\n",
    "        counter = 0\n",
    "        for j in range(len(tM)):\n",
    "            if clf.predict(tM[i]) == y[i]:\n",
    "                counter += 1\n",
    "        accuracy.append(counter/len(tM))\n",
    "    return accuracy\n",
    "#   The following function receives four matrixes and constructs a single matrix\n",
    "#   with the vectors of all the other matrixes and a vector with their grade\n",
    "#   classification.\n",
    "def testEvaluatorMatrix(A, B, C, D):\n",
    "    M = np.array([])\n",
    "    M = np.concatenate((A, B), axis = 0)\n",
    "    M = np.concatenate((M, C), axis = 0)\n",
    "    M = np.concatenate((M, D), axis = 0)\n",
    "    y = np.array([])\n",
    "    y1 = np.zeros(len(A))\n",
    "    y2 = np.zeros(len(B)) + 1\n",
    "    y3 = np.zeros(len(C))  + 2\n",
    "    y4 = np.zeros(len(D)) + 3\n",
    "    y = np.concatenate((y1, y2), axis = 0)\n",
    "    y = np.concatenate((y, y3), axis = 0)\n",
    "    y = np.concatenate((y, y4), axis = 0)\n",
    "    return M, y\n",
    "#   The following function receives four matrixes and constructs a single matrix\n",
    "#   with the vectors of all the other matrixes and a vector with their grade\n",
    "#   classification.\n",
    "def testEvaluatorMatrix3(A, B, C):\n",
    "    M = np.array([])\n",
    "    M = np.concatenate((A, B), axis = 0)\n",
    "    M = np.concatenate((M, C), axis = 0)\n",
    "    y = np.array([])\n",
    "    y1 = np.zeros(len(A))\n",
    "    y2 = np.zeros(len(B)) + 1\n",
    "    y3 = np.zeros(len(C))  + 2\n",
    "    y = np.concatenate((y1, y2), axis = 0)\n",
    "    y = np.concatenate((y, y3), axis = 0)\n",
    "    return M, y\n",
    "#   The following function receives a number (amount of specific sections to retrieve) and\n",
    "#   a dictionary of specific sections.\n",
    "def getNVector(n, A):\n",
    "    rA = {}\n",
    "    counter = 0\n",
    "    stop = n\n",
    "    for (a, avec) in A.items():\n",
    "        if counter < stop: \n",
    "            rA[a] = avec\n",
    "        else:\n",
    "            break\n",
    "        counter += 1\n",
    "    return rA\n",
    "#   The following function receives four matrixes and a number. It returns the\n",
    "#   amount of vectors in the number for each of the matrixes.\n",
    "def getNVectors(n, A, B, C, D):\n",
    "    rA = {}\n",
    "    rB = {}\n",
    "    rC = {}\n",
    "    rD = {}\n",
    "    for (a, avec), (b, bvec), (c, cvec), (d, dvec) in zip (A.items(), B.items(), C.items(), D.items()):\n",
    "        rA[a] = avec\n",
    "        rB[b] = bvec\n",
    "        rC[c] = cvec\n",
    "        rD[d] = dvec\n",
    "    return rA, rB, rC, rD\n",
    "#   The following function receives three matrixes and a number. It returns the\n",
    "#   amount of vectors in the number for each of the matrixes.\n",
    "def get3NVectors(n, A, B, C):\n",
    "    rA = {}\n",
    "    rB = {}\n",
    "    rC = {}\n",
    "    counter = 0\n",
    "    stop = n\n",
    "    for (a, avec), (b, bvec), (c, cvec) in zip (A.items(), B.items(), C.items()):\n",
    "        if counter < stop:\n",
    "            rA[a] = avec\n",
    "            rB[b] = bvec\n",
    "            rC[c] = cvec\n",
    "        else:\n",
    "            break\n",
    "        counter+=1\n",
    "    return rA, rB, rC\n",
    "#   The following function receives two vectors, actual results for the test vector and the\n",
    "#   predicted vector produced by our classifier, it then returns the accuracy report for\n",
    "#   our classifier. Accuracy considered as number of correct predictions divided by total\n",
    "#   number of predictions made.\n",
    "def obtain_accuracy(a, b):\n",
    "    correct = np.where(a == b)\n",
    "    return np.size(correct)/np.size(a)\n",
    "    \n",
    "\n",
    "#   Open the stop words file.\n",
    "sw = openFile(\"stopWords.txt\")\n",
    "#   Curate the stop words.\n",
    "sw = cleanStop(sw)\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'TSUCompleta.xml'\n",
    "with open(s) as fp:\n",
    "    soup = BeautifulSoup(fp, 'xml')\n",
    "    all = soup.find_all('Problema')\n",
    "soup.find_all('Problema')\n",
    "\n",
    "counter = 1\n",
    "problema = \"\"\n",
    "for met in soup.find_all('Problema'):\n",
    "    [s.extract() for s in met.findAll('Problema')]\n",
    "    ######print(\"*Metodologia\", counter)\n",
    "    #####print(met)\n",
    "    problema = problema + str(met) + \"\\n\"\n",
    "    #####print(\"\\n\")\n",
    "    counter += 1\n",
    "problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemTSU = bsMeth('TSUCompleta.xml')\n",
    "problemLic = bsMeth('LicenciaturaCompleto.xml')\n",
    "problemMasters = bsMeth('MaestriaCompleto.xml')\n",
    "problemPhd = bsMeth('DoctoradoCompleto.xml')\n",
    "problemTSU\n",
    "problemLic\n",
    "problemMasters\n",
    "problemPhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Problem Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemTSU = [j for j in problemTSU.split(\"<Problema>\")]\n",
    "problemLic = [j for j in problemLic.split(\"<Problema>\")]\n",
    "problemMasters = [j for j in problemMasters.split('<Problema>')]\n",
    "problemPhd = [j for j in problemPhd.split('<Problema>')]\n",
    "problemTSU\n",
    "problemLic\n",
    "problemMasters\n",
    "problemPhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSU_structured = sepMeth(problemTSU)\n",
    "Lic_structured = sepMeth(problemLic)\n",
    "Masters_structured = sepMeth(problemMasters)\n",
    "Phd_structured = sepMeth(problemPhd)\n",
    "TSU_structured\n",
    "Lic_structured\n",
    "Masters_structured\n",
    "Phd_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSU_structured = cleanVector(TSU_structured)\n",
    "Lic_structured = cleanVector(Lic_structured)\n",
    "Masters_structured = cleanVector(Masters_structured)\n",
    "Phd_structured = cleanVector(Phd_structured)\n",
    "TSU_structured\n",
    "Lic_structured\n",
    "Masters_structured\n",
    "Phd_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Size for the Justification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizesTSU = returnSizes(TSU_structured)\n",
    "sizesLic = returnSizes(Lic_structured)\n",
    "sizesMasters = returnSizes(Masters_structured)\n",
    "sizesPhd = returnSizes(Phd_structured)\n",
    "sizesTSU\n",
    "sizesLic \n",
    "sizesMasters\n",
    "sizesPhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSU_structured = cleanMeth(sw, TSU_structured)\n",
    "Lic_structured = cleanMeth(sw, Lic_structured)\n",
    "Masters_structured = cleanMeth(sw, Masters_structured)\n",
    "Phd_structured = cleanMeth(sw, Phd_structured)\n",
    "TSU_structured\n",
    "Lic_structured\n",
    "Masters_structured\n",
    "Phd_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dictionary: Justification#-List of Words (Easier to handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSU_structured = listMeth(TSU_structured)\n",
    "Lic_structured = listMeth(Lic_structured)\n",
    "Masters_structured = listMeth(Masters_structured)\n",
    "Phd_structured = listMeth(Phd_structured)\n",
    "\n",
    "TSU_structured\n",
    "Lic_structured\n",
    "Masters_structured\n",
    "Phd_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a specific number of vectors to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSU_structured = getNVector(len(TSU_structured), TSU_structured)\n",
    "Lic_structured = getNVector(len(Lic_structured), Lic_structured)\n",
    "Masters_structured = getNVector(len(Masters_structured), Masters_structured)\n",
    "Phd_structured = getNVector(len(Phd_structured), Phd_structured)\n",
    "\n",
    "len(TSU_structured)\n",
    "len(Lic_structured)\n",
    "len(Masters_structured)\n",
    "len(Phd_structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide our data in eighty and twenty percent (This in order to have some experimental data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_TSU, eighty_TSU = divideEightyTwenty(TSU_structured)\n",
    "twenty_Lic, eighty_Lic = divideEightyTwenty(Lic_structured)\n",
    "twenty_Masters, eighty_Masters = divideEightyTwenty(Masters_structured)\n",
    "twenty_Phd, eighty_Phd = divideEightyTwenty(Phd_structured)\n",
    "\n",
    "len(twenty_TSU)\n",
    "len(eighty_TSU)\n",
    "len(twenty_Lic)\n",
    "len(eighty_Lic)\n",
    "len(twenty_Masters)\n",
    "len(eighty_Masters)\n",
    "len(twenty_Phd)\n",
    "len(eighty_Phd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Relative Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyRFTSU = relFreq(twenty_TSU)\n",
    "eightyRFTSU = relFreq(eighty_TSU)\n",
    "twentyRFLic = relFreq(twenty_Lic)\n",
    "eightyRFLic = relFreq(eighty_Lic)\n",
    "twentyRFMasters = relFreq(twenty_Masters)\n",
    "eightyRFMasters = relFreq(eighty_Masters)\n",
    "twentyRFPhd = relFreq(twenty_Phd)\n",
    "eightyRFPhd = relFreq(eighty_Phd)\n",
    "\n",
    "len(twentyRFTSU)\n",
    "len(eightyRFTSU)\n",
    "len(twentyRFLic)\n",
    "len(eightyRFLic)\n",
    "len(twentyRFMasters)\n",
    "len(eightyRFMasters)\n",
    "len(twentyRFPhd)\n",
    "len(eightyRFPhd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common Spanish Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostCommonDic = mostCommon()\n",
    "mostCommonDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Log of the Common Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyLFTSU = logFreq(twenty_TSU, mostCommonDic)\n",
    "eightyLFTSU = logFreq(eighty_TSU, mostCommonDic)\n",
    "twentyLFLic = logFreq(twenty_Lic, mostCommonDic)\n",
    "eightyLFLic = logFreq(eighty_Lic, mostCommonDic)\n",
    "twentyLFMasters = logFreq(twenty_Masters, mostCommonDic)\n",
    "eightyLFMasters = logFreq(eighty_Masters, mostCommonDic)\n",
    "twentyLFPhd = logFreq(twenty_Phd, mostCommonDic)\n",
    "eightyLFPhd = logFreq(eighty_Phd, mostCommonDic)\n",
    "\n",
    "twentyLFTSU\n",
    "eightyLFTSU\n",
    "twentyLFLic\n",
    "eightyLFLic\n",
    "twentyLFMasters\n",
    "eightyLFMasters\n",
    "twentyLFPhd\n",
    "eightyLFPhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = obtainVocSingle(TSU_structured)\n",
    "voc = obtainVocDouble(TSU_structured, Lic_structured)\n",
    "voc = obtainVoc(TSU_structured, Lic_structured, Masters_structured, Phd_structured)\n",
    "len(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding (Dimensionate the Vectors based on the size of the Vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TSU\n",
    "twentyPadRFTSU = dimRelFreq(twentyRFTSU, voc)\n",
    "twentyPadLFTSU = dimRelFreq(twentyLFTSU, voc)\n",
    "eightyPadRFTSU = dimRelFreq(eightyRFTSU, voc)\n",
    "eightyPadLFTSU = dimRelFreq(eightyLFTSU, voc)\n",
    "twentyPadRFTSU\n",
    "eightyPadRFTSU\n",
    "twentyPadLFTSU\n",
    "eightyPadLFTSU\n",
    "# For Lic\n",
    "twentyPadRFLic = dimRelFreq(twentyRFLic, voc)\n",
    "twentyPadLFLic = dimRelFreq(twentyLFLic, voc)\n",
    "eightyPadRFLic = dimRelFreq(eightyRFLic, voc)\n",
    "eightyPadLFLic = dimRelFreq(eightyLFLic, voc)\n",
    "twentyPadRFLic\n",
    "twentyPadLFLic\n",
    "eightyPadRFLic\n",
    "eightyPadLFLic\n",
    "# For Masters\n",
    "twentyPadRFMasters = dimRelFreq(twentyRFMasters, voc)\n",
    "twentyPadLFMasters = dimRelFreq(twentyLFMasters, voc)\n",
    "eightyPadRFMasters = dimRelFreq(eightyRFMasters, voc)\n",
    "eightyPadLFMasters = dimRelFreq(eightyLFMasters, voc)\n",
    "# For Phd\n",
    "twentyPadRFPhd = dimRelFreq(twentyRFPhd, voc)\n",
    "twentyPadLFPhd = dimRelFreq(twentyLFPhd, voc)\n",
    "eightyPadRFPhd = dimRelFreq(eightyRFPhd, voc)\n",
    "eightyPadLFPhd = dimRelFreq(eightyLFPhd, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Local and Global Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSU\n",
    "twentyConTSU = concatenateDictionaries(twentyPadRFTSU, twentyPadLFTSU)\n",
    "eightyConTSU = concatenateDictionaries(eightyPadRFTSU, eightyPadLFTSU)\n",
    "twentyConLic = concatenateDictionaries(twentyPadRFLic, twentyPadLFLic)\n",
    "eightyConLic = concatenateDictionaries(eightyPadRFLic, eightyPadLFLic)\n",
    "twentyConMasters = concatenateDictionaries(twentyPadRFMasters, twentyPadLFMasters)\n",
    "eightyConMasters = concatenateDictionaries(eightyPadRFMasters, eightyPadLFMasters)\n",
    "twentyConPhd = concatenateDictionaries(twentyPadRFPhd, twentyPadLFPhd)\n",
    "eightyConPhd = concatenateDictionaries(eightyPadRFPhd, eightyPadLFPhd)\n",
    "np.array((twentyConLic)).sum()\n",
    "np.array((eightyConLic)).sum()\n",
    "np.array((twentyConMasters)).sum()\n",
    "np.array((eightyConMasters)).sum()\n",
    "np.array((twentyConPhd)).sum()\n",
    "np.array((eightyConPhd)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand and Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HST and Undergraduate\n",
    "twentyPOneTL, twentyMOneTL = comData(twentyConTSU, twentyConLic)\n",
    "eightyPOneTL, eightyMOneTL = comData(eightyConTSU, eightyConLic)\n",
    "np.array((twentyPOneTL)).sum()\n",
    "np.array((twentyMOneTL)).sum()\n",
    "# HST and Masters\n",
    "twentyPOneTM, twentyMOneTM = comData(twentyConTSU, twentyConMasters)\n",
    "eightyPOneTM, eightyMOneTM = comData(eightyConTSU, eightyConMasters)\n",
    "# HST and Phd\n",
    "twentyPOneTP, twentyMOneTP = comData(twentyConTSU, twentyConPhd)\n",
    "eightyPOneTP, eightyMOneTP = comData(eightyConTSU, eightyConPhd)\n",
    "# Undergraduate and Masters\n",
    "twentyPOneUM, twentyMOneUM = comData(twentyConLic, twentyConMasters)\n",
    "eightyPOneUM, eightyMOneUM = comData(eightyConLic, eightyConMasters)\n",
    "# Undergraduate and Phd\n",
    "twentyPOneUP, twentyMOneUP = comData(twentyConLic, twentyConPhd)\n",
    "eightyPOneUP, eightyMOneUP = comData(eightyConLic, eightyConPhd)\n",
    "# Masters and Phd\n",
    "twentyPOneMP, twentyMOneMP = comData(twentyConMasters, twentyConPhd)\n",
    "eightyPOneMP, eightyMOneMP = comData(eightyConMasters, eightyConPhd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append the Data and Create Classification Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HST and Undergraduate\n",
    "TLM_test, tly_test = allTogetherNowDouble(twentyPOneTL, twentyMOneTL)\n",
    "len(TLM_test)\n",
    "len(tly_test)\n",
    "TLM_train, tly_train = allTogetherNowDouble(eightyPOneTL, eightyMOneTL)\n",
    "len(TLM_train)\n",
    "len(tly_train)\n",
    "# HST and Masters\n",
    "TMM_test, tmy_test = allTogetherNowDouble(twentyPOneTM, twentyMOneTM)\n",
    "TMM_train, tmy_train = allTogetherNowDouble(eightyPOneTM, eightyMOneTM)\n",
    "#HST and Phd\n",
    "TPM_test, tpy_test = allTogetherNowDouble(twentyPOneTP, twentyMOneTP)\n",
    "TPM_train, tpy_train = allTogetherNowDouble(eightyPOneTP, eightyMOneTP)\n",
    "#Undergraduate and Masters\n",
    "UMM_test, umy_test = allTogetherNowDouble(twentyPOneUM, twentyMOneUM)\n",
    "UMM_train, umy_train = allTogetherNowDouble(eightyPOneUM, eightyMOneUM)\n",
    "#Undergraduate and PhD\n",
    "UPM_test, upy_test = allTogetherNowDouble(twentyPOneUP, twentyMOneUP)\n",
    "UPM_train, upy_train = allTogetherNowDouble(eightyPOneUP, eightyMOneUP)\n",
    "#Masters and PhD\n",
    "MPM_test, mpy_test = allTogetherNowDouble(twentyPOneMP, twentyMOneMP)\n",
    "MPM_train, mpy_train = allTogetherNowDouble(eightyPOneMP, eightyMOneMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HST and Udergraduate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemedardotapiatellez/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = svm.SVC()\n",
    "svclassifier.fit(TLM_train, tly_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the SVM classifier is: 36.659663865546214 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(TLM_test)\n",
    "\n",
    "print(\"The accuracy value for the SVM classifier is: {} %\".format(obtain_accuracy(tly_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(TLM_train, tly_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurracy value for the KNN classifier is: 41.596638655462186 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(TLM_test)\n",
    "print('The accurracy value for the KNN classifier is: {} %'.format(obtain_accuracy(tly_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(TLM_train, tly_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the Multilayer Perceptron is: 37.39495798319328 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(TLM_test)\n",
    "print(\"The accuracy value for the Multilayer Perceptron is: {} %\".format(obtain_accuracy(tly_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HST and Masters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemedardotapiatellez/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = svm.SVC()\n",
    "svclassifier.fit(TMM_train, tmy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the SVM classifier is: 54.41176470588235 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(TMM_test)\n",
    "print(\"The accuracy value for the SVM classifier is: {} %\".format(obtain_accuracy(tmy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(TMM_train, tmy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurracy value for the KNN classifier is: 55.55555555555556 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(TMM_test)\n",
    "print('The accurracy value for the KNN classifier is: {} %'.format(obtain_accuracy(tmy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(TMM_train, tmy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the Multilayer Perceptron is: 53.18627450980392 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(TMM_test)\n",
    "print(\"The accuracy value for the Multilayer Perceptron is: {} %\".format(obtain_accuracy(tmy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HST and PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = svm.SVC()\n",
    "svclassifier.fit(TPM_train, tpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(TPM_test)\n",
    "print(\"The accuracy value for the SVM classifier is: {} %\".format(obtain_accuracy(tpy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(TPM_train, tpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(TPM_test)\n",
    "print('The accurracy value for the KNN classifier is: {} %'.format(obtain_accuracy(tpy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(TPM_train, tpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(TPM_test)\n",
    "print(\"The accuracy value for the Multilayer Perceptron is: {} %\".format(obtain_accuracy(tpy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undergraduate and Masters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemedardotapiatellez/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = svm.SVC()\n",
    "svclassifier.fit(UMM_train, umy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the SVM classifier is: 57.53968253968254 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(UMM_test)\n",
    "print(\"The accuracy value for the SVM classifier is: {} %\".format(obtain_accuracy(umy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(UMM_train, umy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurracy value for the KNN classifier is: 47.42063492063492 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(UMM_test)\n",
    "print('The accurracy value for the KNN classifier is: {} %'.format(obtain_accuracy(umy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(UMM_train, umy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the Multilayer Perceptron is: 47.817460317460316 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(UMM_test)\n",
    "print(\"The accuracy value for the Multilayer Perceptron is: {} %\".format(obtain_accuracy(umy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undergraduate and PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemedardotapiatellez/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = svm.SVC()\n",
    "svclassifier.fit(UPM_train, upy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the SVM classifier is: 74.48979591836735 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(UPM_test)\n",
    "print(\"The accuracy value for the SVM classifier is: {} %\".format(obtain_accuracy(upy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(UPM_train, upy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurracy value for the KNN classifier is: 28.57142857142857 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(UPM_test)\n",
    "print('The accurracy value for the KNN classifier is: {} %'.format(obtain_accuracy(upy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(UPM_train, upy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the Multilayer Perceptron is: 52.04081632653062 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(UPM_test)\n",
    "print(\"The accuracy value for the Multilayer Perceptron is: {} %\".format(obtain_accuracy(upy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masters and PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemedardotapiatellez/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = svm.SVC()\n",
    "svclassifier.fit(MPM_train, mpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the SVM classifier is: 71.82539682539682 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(MPM_test)\n",
    "print(\"The accuracy value for the SVM classifier is: {} %\".format(obtain_accuracy(mpy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(MPM_train, mpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurracy value for the KNN classifier is: 61.904761904761905 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(MPM_test)\n",
    "print('The accurracy value for the KNN classifier is: {} %'.format(obtain_accuracy(mpy_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha = 1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(MPM_train, mpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy value for the Multilayer Perceptron is: 69.04761904761905 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(MPM_test)\n",
    "print(\"The accuracy value for the Multilayer Perceptron is: {} %\".format(obtain_accuracy(mpy_test, y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
